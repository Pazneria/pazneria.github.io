<!-- AGI Forecasting page with detailed analysis on compute scaling, brain parity,
     recursive self‑improvement and other factors influencing artificial general
     intelligence timelines.  This version integrates rich content from a
     research summary while maintaining the dark aesthetic of the Pazneria
     site. -->

<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>AGI Forecasting – Pazneria</title>
  <!-- Import the site's global styles -->
  <link rel="stylesheet" href="assets/style.css">
  <!-- Inline styles specific to the AGI forecasting content.  These rules
       complement the dark theme defined in assets/style.css and ensure the
       detailed sections below are readable and visually consistent. -->
  <style>
    /* Container for the detailed AGI content */
    .agi-content {
      max-width: 900px;
      margin: 2rem auto;
      padding: 0 1rem;
      line-height: 1.6;
    }
    .agi-content h2 {
      margin-top: 2rem;
      color: var(--accent-color, #00cc88);
      font-size: 1.6rem;
    }
    .agi-content h3 {
      margin-top: 1.5rem;
      color: var(--accent-color, #00cc88);
      font-size: 1.3rem;
    }
    .agi-content p {
      margin-bottom: 1rem;
    }
    .agi-content img {
      width: 100%;
      height: auto;
      margin: 1rem 0;
      border-radius: 4px;
    }
    .agi-content table {
      width: 100%;
      border-collapse: collapse;
      margin: 1rem 0;
    }
    .agi-content th,
    .agi-content td {
      border: 1px solid #444;
      padding: 0.5rem;
      text-align: left;
    }
    .agi-content th {
      background-color: #222;
    }
    .agi-content tbody tr:nth-child(odd) {
      background-color: #111;
    }
    .agi-content ul {
      margin-left: 1.5rem;
      list-style-type: disc;
    }
    .agi-content em {
      color: #aaa;
      font-size: 0.85rem;
    }
  </style>
</head>
<body>
  <!-- Site navigation header -->
  <header>
    <nav class="site-nav">
      <a href="index.html" class="logo">Pazneria</a>
      <ul class="nav-list">
        <li><a href="index.html" class="nav-link">Home</a></li>
        <li><a href="agi.html" class="nav-link">AGI Forecasting</a></li>
        <li><a href="game.html" class="nav-link">Game</a></li>
        <li><a href="about.html" class="nav-link">About</a></li>
        <li><a href="contact.html" class="nav-link">Contact</a></li>
      </ul>
    </nav>
  </header>

  <main>
    <!-- Introductory hero section -->
    <section class="hero">
      <h1>AGI Forecasting</h1>
      <p>
        When will machines rival the breadth of human intelligence? At Pazneria we
        explore trajectories for the emergence of artificial general intelligence
        by analysing compute scaling, estimates of brain parity, recursive
        self‑improvement, memory architectures, embodiment and energy
        infrastructure. The content below summarises our latest synthesis of
        technical reports and will be updated as new evidence emerges.
      </p>
    </section>

    <!-- Countdown section -->
    <section>
      <h2>Countdown to AGI</h2>
      <p>
        Our current central forecast places disembodied AGI around
        <strong>1 January 2035</strong>. The live countdown below reflects this
        estimate and will be revised as our forecast evolves.
      </p>
      <div class="countdown-container">
        <div class="countdown-box">
          <span id="days">--</span>
          <small>Days</small>
        </div>
        <div class="countdown-box">
          <span id="hours">--</span>
          <small>Hours</small>
        </div>
        <div class="countdown-box">
          <span id="minutes">--</span>
          <small>Minutes</small>
        </div>
        <div class="countdown-box">
          <span id="seconds">--</span>
          <small>Seconds</small>
        </div>
      </div>
    </section>

    <!-- Detailed AGI forecasting analysis -->
    <section class="agi-content">
      <h2>Forecasting AGI: compute trends, brain parity and self‑improvement</h2>
      <p><strong>Last updated: July 2025</strong></p>
      <p>
        Advances in large language models and multimodal AI raise pressing
        questions about when artificial general intelligence (AGI) might
        emerge. This page synthesises information from recent technical
        reports on compute scaling, human brain computational requirements,
        recursive self‑improvement (RSI), memory architectures,
        embodiment and energy infrastructure. It presents our current AGI
        timeline forecast and will be updated as new data become available.
      </p>

      <!-- Compute scaling and brain parity section -->
      <h2>1 Compute scaling and brain parity</h2>
      <h3>Training FLOPs Over Time</h3>
      <p>
        Over the past decade, the total compute used to train frontier
        language models has grown explosively, far outpacing Moore’s Law.
        OpenAI’s GPT‑3 (2020) required on the order of <em>3×10<sup>23</sup></em>
        FLOPs for training, whereas its successor GPT‑4 (2023) consumed an
        estimated <em>10<sup>25</sup></em> FLOPs – roughly 30× more compute than
        GPT‑3. This reflects an overall exponential scaling trend: from 2016
        to 2023 the training compute for milestone models increased by about
        <strong>8 orders of magnitude</strong>, rising from the petaflop scale to
        nearly 10<sup>26</sup> total operations for the largest 2023 models.
        In practice, each new generation of model (e.g. GPT‑2 → GPT‑3 →
        GPT‑4) has often needed about <strong>10×</strong> more FLOPs than its
        predecessor to reach higher performance, underscoring the steep compute
        requirements of pushing state‑of‑the‑art capabilities.
      </p>
      <p><img src="training_flops_trend.png" alt="Training compute trend"></p>
      <p>
        <em>Figure 1 – Illustration of training compute scaling. The shaded band
        shows the exponential increase in training FLOPs. Dotted lines mark
        improvements in algorithmic efficiency.</em>
      </p>

      <h3>Inference FLOPs per Token and FLOPs/sec Throughput</h3>
      <p>
        Large language models also demand enormous compute at inference time on
        a per‑token basis. For example, <strong>GPT‑3</strong> (175 B parameters)
        requires roughly <em>3.5×10<sup>11</sup></em> FLOPs to generate a single
        token, whereas <strong>GPT‑4</strong> (with a larger ~1.8 T parameter
        Mixture‑of‑Experts architecture) is around
        <em>10<sup>12</sup></em> FLOPs per token – about 3× higher. Anthropic
        Claude 3.5 (2024) has a similar size to GPT‑3 (≈175 B parameters) and
        likewise uses on the order of <em>3.5×10<sup>11</sup></em> FLOPs per token
        in its dense form. Google’s Gemini 1.5 (2024) employs sparse
        activation to reduce compute, so despite possibly trillions of
        parameters total, only a fraction are active per token – yielding an
        effective per‑token cost on the same order as GPT‑4, roughly
        10<sup>12</sup> FLOPs per token. These figures illustrate that each
        token generated by a frontier model entails hundreds of billions to a
        trillion‑plus math operations.
      </p>
      <p>
        When accumulated over time, the inference throughput becomes
        astronomical. At a generation rate of about <strong>100 tokens per
        second</strong>, GPT‑4 would require on the order of
        <em>10<sup>14</sup></em> FLOPs/sec of compute, whereas Claude 3.5 would
        need ~3.5×10<sup>13</sup> FLOPs/sec for the same rate. In other words,
        serving a single large model can easily consume tens of trillions of
        operations each second in deployment. Such high throughput generally
        demands massive parallelism: for instance, GPT‑4 is reported to run
        across roughly 128 GPUs in inference to sustain ~100 tokens per
        second. This illustrates the extreme compute intensity of running
        cutting‑edge LLMs – even after training, their inference is costly on
        the order of petaflop/s‑scale computing for real‑time use.
      </p>
      <p><img src="inference_flops_trend.png" alt="Inference compute and brain parity"></p>
      <p>
        <em>Figure 2 – Projected raw vs. effective inference compute. The
        orange line (effective compute) grows faster than the yellow line
        (raw compute) due to algorithmic efficiency. The dashed line marks the
        estimated human brain parity at 10<sup>16</sup> FLOPs/s. The effective
        compute curve crosses this threshold around 2035–2036.</em>
      </p>

      <h3>Comparison to Human Brain Estimates</h3>
      <p>
        The <strong>human brain</strong>’s computational throughput is difficult
        to pin down, but most estimates place it on the order of
        10<sup>15</sup>–10<sup>16</sup> FLOPs per second for the whole brain’s
        activity. Different modelling approaches converge on this ballpark. A
        <strong>mechanistic</strong> estimate (treating each neural spike as an
        “operation”) with ~10<sup>14</sup>–10<sup>15</sup> synapses firing at
        tens of hertz yields roughly 10<sup>15</sup>–10<sup>16</sup> operations
        per second. Likewise, <strong>functional</strong> or task‑based analyses
        (e.g. analysing the brain’s performance on vision or auditory tasks)
        tend to imply a similar scale: for instance, Kurzweil estimated
        ~10<sup>14</sup> FLOPs/s for human‑level pattern recognition,
        extrapolating to ~10<sup>16</sup> FLOPs/s for overall brain capacity.
        In contrast, extremely detailed brain simulations that account for
        every molecular interaction produce upper‑bound estimates up to
        ~10<sup>25</sup> FLOPs/s, but these are likely overkill for functional
        equivalence. Overall, recent surveys argue that on the order of
        10<sup>15</sup> FLOPs/s is sufficient to match the brain’s
        computational power for intelligent behaviour, and almost certainly
        less than 10<sup>18</sup> required if we avoid low‑level biochemical
        emulation. For consistency, AI researchers often take
        10<sup>15</sup>–10<sup>16</sup> FLOPs/s as a representative
        “brain‑level” compute throughput.
      </p>
      <p>
        How do current AI models stack up against this benchmark? In raw
        computational terms, a deployed model like GPT‑4 (running on dozens of
        top‑end GPUs) might achieve on the order of 10<sup>14</sup> FLOPs/s of
        inference throughput – still one to two orders of magnitude below the
        human brain’s ~10<sup>16</sup> FLOPs/s scale. More striking is the
        difference in <strong>training</strong> efficiency: the brain essentially
        “trains” in real time using the same ~10<sup>16</sup> FLOPs/s it uses
        for inference over the course of a lifetime (~10<sup>8</sup> seconds
        of experience). In contrast, an LLM like GPT‑4 expends on the order
        of 10<sup>25</sup> FLOPs in a separate training phase to learn from
        data before it ever sees a user query. This implies that current AI
        systems use vastly more total compute to reach human‑like performance
        on cognitive tasks. One analysis highlighted an “efficiency gap” of
        roughly <strong>seven orders of magnitude</strong> between the brain’s
        learning ability and that of a transformer trained via gradient
        descent. In sum, the human brain achieves incredible cognitive
        output with ~10<sup>15</sup>–10<sup>16</sup> FLOPs/sec and ~20 W of
        power – a level of efficiency that today’s AI can only approach in
        narrow bursts and with far greater energy and compute expenditure.
      </p>
      <p><img src="brain_parity_window.png" alt="Brain parity window"></p>
      <p>
        <em>Figure 3 – Brain parity window. Shaded bands show mechanistic/
        functional estimates (~10<sup>15</sup>–10<sup>18</sup> FLOPs/s) and
        simulation‑level estimates (~10<sup>18</sup>–10<sup>22</sup> FLOPs/s).
        The effective AI compute curve enters the lower band around 2035.</em>
      </p>

      <h3>Projection Window for Brain Parity</h3>
      <p>
        What would it take for AI systems to reach <strong>brain parity</strong>
        in compute – i.e. to match the human brain’s effective
        10<sup>16</sup> FLOPs/sec throughput? Extrapolating current trends
        provides a tentative timeline. On the hardware side, the available
        <strong>raw FLOPs/s</strong> for frontier models has been climbing by
        roughly <strong>2× per year</strong> recently (thanks to faster GPUs/TPUs
        and larger model clusters). On the algorithmic side, new model
        architectures and training improvements have been yielding even greater
        gains in <strong>effective compute efficiency</strong> – roughly
        <strong>3× improvement per year</strong> in how much “intelligent work”
        is accomplished per FLOP. If we assume these rates (~2× yearly
        increase in available FLOPs and ~3× in efficiency) continue, that
        implies an overall ~6× increase in effective performance per year.
        Under such compound growth, the compute gap could close surprisingly
        soon.
      </p>
      <p>
        Indeed, a simple projection suggests that by the mid‑2030s AI models
        might achieve <strong>brain‑level throughput</strong>. For instance,
        starting from ~3×10<sup>13</sup> FLOPs/s in 2020 (GPT‑3’s inference at
        ~100 tokens per second) and doubling raw power each year, we’d reach
        ~10<sup>18</sup> FLOPs/s of hardware by ~2035. If simultaneously each
        FLOP is made ~3× more useful every year via algorithmic advances,
        the <strong>effective</strong> compute – i.e. brain‑equivalent FLOPs/s –
        grows even faster. One detailed scenario forecasted that by around
        <strong>2036</strong> a frontier model could reach ~10<sup>16</sup>
        effective FLOPs/s, achieving parity with a human brain’s throughput.
        In that projection, the model might be using on the order of
        10<sup>18</sup> raw FLOPs/s by 2036 (a quintillion operations per
        second across its distributed hardware) but would only need to be
        about <strong>1% as algorithmically efficient</strong> as the brain to
        produce equivalent cognitive output. Notably, the effective
        performance grows much faster than raw FLOPs alone due to the
        compounding of efficiency gains – the curve for brain‑equivalent
        FLOPs/s accelerates and crosses the human baseline earlier than the
        raw hardware curve would by itself.
      </p>
      <p>
        Of course, these extrapolations are speculative. They assume current
        scaling trends persist uninterrupted. In reality, hardware
        improvements could slow down, or algorithmic breakthroughs might
        plateau, pushing out the timeline for parity. Conversely, surprise
        innovations (e.g. radically better architectures or new computing
        paradigms) could pull parity in sooner. That said, the overall
        trajectory is clear: the gap is shrinking. Each year, our machines
        get roughly twice as capable in brute‑force FLOPs and additionally
        more efficient in how they leverage those FLOPs for intelligence. This
        compounding progress suggests that achieving brain‑like
        computational prowess is a matter of “when, not if” assuming no
        fundamental barriers emerge.
      </p>

      <!-- End compute scaling and brain parity section -->

      <!-- Recursive self‑improvement section -->
      <h2>2 Recursive self‑improvement (RSI)</h2>
      <p>
        RSI refers to AI systems that iteratively improve their code, model
        or behaviour. Early prototypes include agents that write their own
        functions (e.g. Voyager, SWE‑Agent), frameworks that use
        self‑reflection to fix mistakes, and models that fine‑tune themselves
        using self‑generated solutions.
      </p>
      <p>
        The RSI report speculates that once an AGI‑level system is developed
        (perhaps by 2030), recursive self‑improvement could push it to
        super‑human performance within months. This “hard takeoff” would
        drastically shorten the time between achieving AGI and reaching
        super‑intelligence.
      </p>
      <p><img src="rsi_timeline.png" alt="RSI timeline"></p>
      <p>
        <em>Figure 4 – Hypothetical RSI timeline. Early prototypes appear around
        2023–2024, broader agent frameworks by 2026, AGI‑level RSI around 2030
        and potential super‑intelligence by 2031.</em>
      </p>

      <!-- Memory architectures section -->
      <h2>3 Memory architectures</h2>
      <p>
        Today’s language models are largely stateless, but new memory
        mechanisms are emerging: episodic user memory, external vector
        databases (retrieval‑augmented generation), scratchpads for
        chain‑of‑thought and agentic frameworks that persist state across tool
        calls. Research is pushing toward million‑token context windows and
        memory‑augmented transformers.
      </p>
      <p>
        The memory report argues that persistent memory could shorten AGI
        timelines by 5–10 years. By enabling lifelong learning and
        cumulative knowledge, memory may bend the compute scaling curve and
        allow smaller models with external memory to match larger models.
      </p>

      <!-- Embodiment and multi‑modal integration section -->
      <h2>4 Embodiment and multi‑modal integration</h2>
      <p>
        Some researchers insist that sensorimotor grounding is essential for
        AGI, citing the richness of physical experience. The Stanford AI100
        study predicted service robots by 2030 but anticipated that reliable,
        general‑purpose home robots would still be elusive. If physical
        embodiment is required, AGI might not emerge until mid‑century.
      </p>
      <p>
        On the other hand, multi‑modal models like GPT‑4o, Gemini 1.5 and
        Claude 3 Opus already handle text, images, audio and actions. When
        combined with memory and tool use, these systems could achieve
        disembodied AGI within a decade. A hybrid scenario envisions
        disembodied AGI first (within 5–15 years), followed by embodied AGI
        decades later.
      </p>

      <!-- Energy infrastructure section -->
      <h2>5 Energy infrastructure</h2>
      <p>
        Compute scaling hinges on electricity supply. An aggressive U.S.
        scenario projects data‑centre consumption of ~500 TWh/year by 2028
        (≈10% of U.S. electricity). Such growth demands significant grid and
        transmission upgrades; delays in permitting and supply chains could
        limit AI compute and slow AGI progress. Shortages of transformers,
        power equipment and GPUs pose additional bottlenecks.
      </p>

      <!-- AGI timeline scenarios section -->
      <h2>6 AGI timeline scenarios</h2>
      <p>
        The interplay of compute scaling, memory, RSI, embodiment and
        infrastructure yields several plausible AGI emergence scenarios. We
        model three rough timelines (not literal probabilities):
      </p>
      <table>
        <thead>
          <tr>
            <th>Scenario</th>
            <th>Description</th>
            <th>Mean year (σ)</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td><strong>RSI‑Turbo</strong></td>
            <td>
              AGI appears ~2029–2031; memory and RSI drive rapid
              self‑improvement, and super‑intelligence follows within months.
            </td>
            <td>2030 (σ≈1.5 yrs)</td>
          </tr>
          <tr>
            <td><strong>Functional‑Scaling</strong></td>
            <td>
              AGI emerges 2033–2037 via continued compute scaling and
              functional parity. Memory and multi‑modal integration gradually
              bridge cognitive gaps.
            </td>
            <td>2035 (σ≈2 yrs)</td>
          </tr>
          <tr>
            <td><strong>Embodied‑Path</strong></td>
            <td>
              AGI requires sensorimotor grounding; disembodied AI excels
              earlier, but true AGI appears 2045–2055.
            </td>
            <td>2050 (σ≈5 yrs)</td>
          </tr>
        </tbody>
      </table>
      <p><img src="agi_emergence_scenarios.png" alt="AGI emergence scenarios"></p>
      <p>
        <em>Figure 5 – AGI emergence scenarios represented as probability
        curves. The RSI‑Turbo peak around 2030 assumes strong self‑improvement;
        the Functional‑Scaling peak around 2035 aligns with current compute
        projections; the Embodied‑Path curve peaks around 2050 for physical
        AGI.</em>
      </p>

      <!-- Our forecast section -->
      <h2>7 Our current forecast</h2>
      <p>
        Based on the evidence above, our <strong>central forecast</strong>
        places disembodied AGI achieving functional parity with human cognition
        between 2033 and 2037, with a median around <strong>2035</strong>.
        We assign roughly 30% probability to an earlier arrival (~2030)
        driven by RSI and memory breakthroughs, and a similar probability to a
        later arrival (>2045) if physical embodiment or infrastructural
        constraints dominate. As of July 2025, the mid‑point AGI arrival is
        about <strong>10 years away</strong>.
      </p>
      <p>
        This forecast will evolve as new data emerge. The countdown timer at
        the top of this page counts down to our current central estimate
        (1 January 2035). As progress accelerates or slows, we will update the
        date accordingly.
      </p>

      <!-- Caveats section -->
      <h2>8 Caveats</h2>
      <ul>
        <li>
          <strong>Uncertainty:</strong> Brain FLOP estimates vary by many orders
          of magnitude, and algorithmic breakthroughs or paradigm shifts
          (e.g. neuromorphic hardware) could change timelines drastically.
        </li>
        <li>
          <strong>Memory and alignment:</strong> Persistent memory may
          accelerate progress, but aligning long‑term AI behaviour remains
          challenging.
        </li>
        <li>
          <strong>Infrastructure:</strong> Energy and component bottlenecks
          could limit compute growth. Government policies and global
          competition introduce additional uncertainty.
        </li>
        <li>
          <strong>Embodiment:</strong> If physical interaction is essential,
          AGI may be decades away. Disembodied AGI could still have profound
          societal impacts long before robots match human dexterity.
        </li>
      </ul>
      <p>
        <strong>Disclaimer:</strong> This forecast is speculative and for
        research purposes only. It does not represent a guarantee of future
        outcomes.
      </p>
    </section>
  </main>

  <!-- Site footer -->
  <footer>
    <p>&copy; <span id="year"></span> Pazneria. All rights reserved.</p>
  </footer>

  <!-- Countdown and footer year scripts -->
  <script>
    // Update the year in the footer
    document.getElementById('year').textContent = new Date().getFullYear();
    // Set the target date for AGI arrival. This is our current central
    // estimate and will change as our forecast is updated.
    const targetDate = new Date('2035-01-01T00:00:00Z');
    const daysEl = document.getElementById('days');
    const hoursEl = document.getElementById('hours');
    const minutesEl = document.getElementById('minutes');
    const secondsEl = document.getElementById('seconds');

    function updateCountdown() {
      const now = new Date();
      const diff = targetDate - now;
      if (diff <= 0) {
        daysEl.textContent = hoursEl.textContent = minutesEl.textContent = secondsEl.textContent = '0';
        return;
      }
      const days = Math.floor(diff / (1000 * 60 * 60 * 24));
      const hours = Math.floor((diff / (1000 * 60 * 60)) % 24);
      const minutes = Math.floor((diff / (1000 * 60)) % 60);
      const seconds = Math.floor((diff / 1000) % 60);
      daysEl.textContent = String(days).padStart(2, '0');
      hoursEl.textContent = String(hours).padStart(2, '0');
      minutesEl.textContent = String(minutes).padStart(2, '0');
      secondsEl.textContent = String(seconds).padStart(2, '0');
    }
    updateCountdown();
    setInterval(updateCountdown, 1000);
  </script>
</body>
</html>
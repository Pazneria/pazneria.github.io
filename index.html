<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Pazneria Blog</title>
  <style>
    body { margin: 0; font-family: Arial, sans-serif; }
    /* Navigation tabs */
    .nav-tabs { display: flex; background-color: #4caf50; box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1); }
    .nav-tabs button { flex: 1; padding: 14px 16px; border: none; background: inherit; color: white; font-size: 16px; cursor: pointer; transition: background-color 0.3s ease; }
    .nav-tabs button:hover { background-color: #45a049; }
    .nav-tabs button.active { background-color: #2e7d32; }
    /* Tab content */
    .tab-content { display: none; padding: 20px; animation: fadeEffect 0.5s; min-height: calc(100vh - 50px); }
    .tab-content.active { display: block; }
    @keyframes fadeEffect { from { opacity: 0; } to { opacity: 1; } }
    /* Countdown specific styles */
    #sticky-countdown { position: sticky; top: 0; background: rgba(255, 255, 255, 0.8); display: block; padding: 10px; z-index: 1000; font-size: 1.2rem; font-weight: bold; text-align:center; }
    /* AGI section styles */
    .agi-section { max-width: 900px; margin: 20px auto; padding: 10px; }
    .agi-section img { display: block; max-width: 100%; height: auto; margin: 20px auto; }
    .agi-section table { width: 100%; border-collapse: collapse; margin: 1rem 0; }
    .agi-section th, .agi-section td { border: 1px solid #ddd; padding: 8px; text-align: left; }
    .agi-section th { background-color: #f0f8ff; }
  </style>
</head>
<body>
  <div class="nav-tabs">
    <button class="active" data-tab-target="home">Home</button>
    <button data-tab-target="countdown">AGI Countdown</button>
    <button data-tab-target="about">About</button>
    <button data-tab-target="projects">Projects</button>
    <button data-tab-target="contact">Contact</button>
  </div>

  <!-- Home Tab -->
  <div id="home" class="tab-content active">
    <h1>Welcome to Pazneria Blog</h1>
    <p>This is the homepage. Please check the AGI Countdown tab to see our research on the timeline for artificial general intelligence.</p>
  </div>

  <!-- AGI Countdown Tab -->
  <div id="countdown" class="tab-content">
    <div id="sticky-countdown"><span id="agi-countdown">Loading AGI countdown...</span></div>
    <div class="agi-section">
<h2>Forecasting AGI: compute trends, brain parity and self‑improvement</h2>

    <p><strong>Last updated: July 2025</strong></p>
    
    <p>Advances in large language models and multimodal AI raise pressing questions about when artificial general intelligence (AGI) might emerge.  This page synthesises information from recent technical reports on compute scaling, human brain computational requirements, recursive self‑improvement (RSI), memory architectures, embodiment and energy infrastructure.  It presents our current AGI timeline forecast and will be updated as new data become available.</p>

    <h2>1&nbsp;Training compute scaling</h2>
    <p>Frontier AI models have exhibited an exponential rise in training FLOPs.  GPT‑3 (2020) used roughly 3×10<sup>23</sup> FLOPs in training, whereas GPT‑4 (2023) likely used on the order of 10<sup>25</sup> FLOPs【984205347748898†L44-L58】.  Each new generation has required ~10× more FLOPs than its predecessor【984205347748898†L44-L58】, even as algorithmic efficiency improves (compute to reach a fixed performance roughly halves every 8–12 months【984205347748898†L69-L114】).  </p>
    <p><img src="training_flops_trend.png" alt="Training compute trend" /></p>
    <p><em>Figure 1 – Illustration of training compute scaling.  The shaded band shows the exponential increase in training FLOPs.  Dotted lines mark improvements in algorithmic efficiency.</em></p>

    <h2>2&nbsp;Inference compute and brain parity</h2>
    <p>Inference cost per token scales with active parameters.  GPT‑3 uses about 3.5×10<sup>11</sup> FLOPs per token, and GPT‑4’s mixture‑of‑experts architecture requires roughly 10<sup>12</sup> FLOPs per token【842880321965119†L0-L25】.  Running at 100 tokens per second yields inference throughput on the order of 10<sup>13–14</sup> FLOPs/s【842880321965119†L53-L60】.  Hardware and architectural advances are improving raw FLOPs/s by ~3× every few years【842880321965119†L100-L117】.</p>
    <p>The human brain’s effective cognitive throughput is estimated around 10<sup>15–16</sup> FLOPs/s【984205347748898†L30-L41】.  Mechanistic and functional analyses put the range at roughly 10<sup>15–17</sup> FLOPs/s【562061693347473†L37-L96】, while whole‑brain simulation might require 10<sup>18</sup> FLOPs/s【562061693347473†L288-L350】.  </p>
    <p><img src="inference_flops_trend.png" alt="Inference compute and brain parity" /></p>
    <p><em>Figure 2 – Projected raw vs. effective inference compute.  The orange line (effective compute) grows faster than the yellow line (raw compute) due to algorithmic efficiency.  The dashed line marks the estimated human brain parity at 10<sup>16</sup> FLOPs/s.  The effective compute curve crosses this threshold around 2035–2036【842880321965119†L292-L335】.</em></p>

    <p><img src="brain_parity_window.png" alt="Brain parity window" /></p>
    <p><em>Figure 3 – Brain parity window.  Shaded bands show mechanistic/functional estimates (~10<sup>15</sup>–10<sup>18</sup> FLOPs/s)【562061693347473†L37-L96】 and simulation‑level estimates (~10<sup>18</sup>–10<sup>22</sup> FLOPs/s)【562061693347473†L288-L332】.  The effective AI compute curve enters the lower band around 2035.</em></p>

    <h2>3&nbsp;Recursive self‑improvement (RSI)</h2>
    <p>RSI refers to AI systems that iteratively improve their code, model or behaviour.  Early prototypes include agents that write their own functions (Voyager, SWE‑Agent)【62982452424681†L28-L44】, frameworks that use self‑reflection to fix mistakes【62982452424681†L49-L89】, and models that fine‑tune themselves using self‑generated solutions【62982452424681†L100-L113】.  </p>
    <p>The RSI report speculates that once an AGI‑level system is developed (perhaps by 2030), recursive self‑improvement could push it to super‑human performance within months【62982452424681†L960-L993】.  This “hard takeoff” would drastically shorten the time between achieving AGI and reaching super‑intelligence.</p>
    <p><img src="rsi_timeline.png" alt="RSI timeline" /></p>
    <p><em>Figure 4 – Hypothetical RSI timeline.  Early prototypes appear around 2023–2024, broader agent frameworks by 2026, AGI‑level RSI around 2030 and potential super‑intelligence by 2031【62982452424681†L960-L993】.</em></p>

    <h2>4&nbsp;Memory architectures</h2>
    <p>Today’s LLMs are largely stateless, but new memory mechanisms are emerging: episodic user memory, external vector databases (retrieval‑augmented generation), scratchpads for chain‑of‑thought and agentic frameworks that persist state across tool calls【677865633633646†L0-L33】【677865633633646†L80-L105】.  Research is pushing toward million‑token context windows and memory‑augmented transformers【677865633633646†L110-L140】.  </p>
    <p>The Memory report argues that persistent memory could shorten AGI timelines by 5–10 years【677865633633646†L380-L470】.  By enabling lifelong learning and cumulative knowledge, memory may bend the compute scaling curve and allow smaller models with external memory to match larger models【677865633633646†L403-L417】.</p>

    <h2>5&nbsp;Embodiment and multi‑modal integration</h2>
    <p>Some researchers insist that sensorimotor grounding is essential for AGI【883213420231783†L20-L40】, citing the richness of physical experience.  The Stanford AI100 study predicted service robots by 2030 but anticipated that reliable, general‑purpose home robots would still be elusive【883213420231783†L634-L641】.  If physical embodiment is required, AGI might not emerge until mid‑century【883213420231783†L634-L653】.</p>
    <p>On the other hand, multi‑modal models like GPT‑4o, Gemini 1.5 and Claude 3 Opus already handle text, images, audio and actions【526013081930174†L0-L30】.  When combined with memory and tool use, these systems could achieve disembodied AGI within a decade【526013081930174†L26-L30】.  A hybrid scenario envisions disembodied AGI first (within 5–15 years), followed by embodied AGI decades later【883213420231783†L688-L742】.</p>

    <h2>6&nbsp;Energy infrastructure</h2>
    <p>Compute scaling hinges on electricity supply.  An aggressive U.S. scenario projects data‑center consumption of ~500 TWh/year by 2028 (≈10% of U.S. electricity)【124710196490884†L10-L25】.  Such growth demands significant grid and transmission upgrades; delays in permitting and supply chains could limit AI compute and slow AGI progress【124710196490884†L755-L779】.  Shortages of transformers, power equipment and GPUs pose additional bottlenecks【124710196490884†L803-L833】.</p>

    <h2>7&nbsp;AGI timeline scenarios</h2>
    <p>The interplay of compute scaling, memory, RSI, embodiment and infrastructure yields several plausible AGI emergence scenarios.  We model three rough timelines (not literal probabilities):</p>
    <table>
      <thead>
        <tr><th>Scenario</th><th>Description</th><th>Mean year (σ)</th></tr>
      </thead>
      <tbody>
        <tr><td><strong>RSI‑Turbo</strong></td><td>AGI appears ~2029–2031; memory and RSI drive rapid self‑improvement, and super‑intelligence follows within months【62982452424681†L960-L993】.</td><td>2030 (σ≈1.5 yrs)</td></tr>
        <tr><td><strong>Functional‑Scaling</strong></td><td>AGI emerges 2033–2037 via continued compute scaling and functional parity.  Memory and multi‑modal integration gradually bridge cognitive gaps【842880321965119†L292-L335】.</td><td>2035 (σ≈2 yrs)</td></tr>
        <tr><td><strong>Embodied‑Path</strong></td><td>AGI requires sensorimotor grounding; disembodied AI excels earlier, but true AGI appears 2045–2055【883213420231783†L634-L653】.</td><td>2050 (σ≈5 yrs)</td></tr>
      </tbody>
    </table>

    <p><img src="agi_emergence_scenarios.png" alt="AGI emergence scenarios" /></p>
    <p><em>Figure 5 – AGI emergence scenarios represented as probability curves.  The RSI‑Turbo peak around 2030 assumes strong self‑improvement; the Functional‑Scaling peak around 2035 aligns with current compute projections; the Embodied‑Path curve peaks around 2050 for physical AGI.</em></p>

    <h2>8&nbsp;Our current forecast</h2>
    <p>Based on the evidence above, our **central forecast** places disembodied AGI achieving functional parity with human cognition between 2033 and 2037, with a median around **2035**.  We assign roughly 30% probability to an earlier arrival (~2030) driven by RSI and memory breakthroughs, and a similar probability to a later arrival (>2045) if physical embodiment or infrastructural constraints dominate.  As of July 2025, the mid‑point AGI arrival is about **10 years away**.</p>

    <p>This forecast will evolve as new data emerge.  The countdown timer at the top of this page counts down to our current central estimate (1 January 2035).  As progress accelerates or slows, we will update the date accordingly.</p>

    <h2>9&nbsp;Caveats</h2>
    <ul>
      <li><strong>Uncertainty:</strong> Brain FLOP estimates vary by many orders of magnitude【562061693347473†L37-L96】, and algorithmic breakthroughs or paradigm shifts (e.g. neuromorphic hardware) could change timelines drastically.</li>
      <li><strong>Memory and alignment:</strong> Persistent memory may accelerate progress【677865633633646†L380-L470】, but aligning long‑term AI behaviour remains challenging【63576129267672†L1048-L1090】.</li>
      <li><strong>Infrastructure:</strong> Energy and component bottlenecks could limit compute growth【124710196490884†L755-L833】.  Government policies and global competition introduce additional uncertainty【124710196490884†L871-L895】.</li>
      <li><strong>Embodiment:</strong> If physical interaction is essential, AGI may be decades away【883213420231783†L634-L653】.  Disembodied AGI could still have profound societal impacts long before robots match human dexterity【883213420231783†L688-L740】.</li>
    </ul>

    <p><strong>Disclaimer:</strong> This forecast is speculative and for research purposes only.  It does not represent a guarantee of future outcomes.</p>
    </div>
  </div>

  <!-- About Tab -->
  <div id="about" class="tab-content">
    <h2>About</h2>
    <p>This site discusses AI, technology and personal projects. The AGI Countdown tab provides a forecast for artificial general intelligence based on current research.</p>
  </div>

  <!-- Projects Tab -->
  <div id="projects" class="tab-content">
    <h2>Projects</h2>
    <p>Coming soon!</p>
  </div>

  <!-- Contact Tab -->
  <div id="contact" class="tab-content">
    <h2>Contact</h2>
    <p>You can reach me via GitHub issues.</p>
  </div>

  <script>
    // Tab switching logic
    const tabs = document.querySelectorAll('.nav-tabs button');
    const contents = document.querySelectorAll('.tab-content');
    tabs.forEach(tab => {
      tab.addEventListener('click', () => {
        tabs.forEach(t => t.classList.remove('active'));
        tab.classList.add('active');
        const target = tab.getAttribute('data-tab-target');
        contents.forEach(c => { c.classList.remove('active'); });
        document.getElementById(target).classList.add('active');
      });
    });

    // Countdown timer (counts down to Jan 1, 2035 by default)
    const targetDate = new Date('2035-01-01T00:00:00Z').getTime();
    const countdownSpan = document.getElementById('agi-countdown');
    function updateCountdown() {
      const now = new Date().getTime();
      const distance = targetDate - now;
      if (distance < 0) { countdownSpan.textContent = 'AGI has arrived!'; return; }
      const days = Math.floor(distance / (1000 * 60 * 60 * 24));
      const hours = Math.floor((distance % (1000 * 60 * 60 * 24)) / (1000 * 60 * 60));
      const minutes = Math.floor((distance % (1000 * 60 * 60)) / (1000 * 60));
      const seconds = Math.floor((distance % (1000 * 60)) / 1000);
      countdownSpan.textContent = days + 'd ' + hours + 'h ' + minutes + 'm ' + seconds + 's until AGI (est.)';
    }
    updateCountdown();
    setInterval(updateCountdown, 1000);
  </script>
</body>
</html>
